apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: '2'
    meta.helm.sh/release-name: rke2-coredns
    meta.helm.sh/release-namespace: kube-system
  creationTimestamp: '2025-06-10T20:16:30Z'
  generation: 2
  labels:
    app.kubernetes.io/instance: rke2-coredns
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: rke2-coredns-autoscaler
    helm.sh/chart: rke2-coredns-1.42.000
    k8s-app: kube-dns-autoscaler
    kubernetes.io/cluster-service: 'true'
    kubernetes.io/name: CoreDNS
  managedFields:
    - apiVersion: apps/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:meta.helm.sh/release-name: {}
            f:meta.helm.sh/release-namespace: {}
          f:labels:
            .: {}
            f:app.kubernetes.io/instance: {}
            f:app.kubernetes.io/managed-by: {}
            f:app.kubernetes.io/name: {}
            f:helm.sh/chart: {}
            f:k8s-app: {}
            f:kubernetes.io/cluster-service: {}
            f:kubernetes.io/name: {}
        f:spec:
          f:progressDeadlineSeconds: {}
          f:replicas: {}
          f:revisionHistoryLimit: {}
          f:selector: {}
          f:strategy:
            f:rollingUpdate:
              .: {}
              f:maxSurge: {}
              f:maxUnavailable: {}
            f:type: {}
          f:template:
            f:metadata:
              f:annotations:
                .: {}
                f:checksum/configmap: {}
                f:scheduler.alpha.kubernetes.io/tolerations: {}
              f:labels:
                .: {}
                f:app.kubernetes.io/instance: {}
                f:app.kubernetes.io/name: {}
                f:k8s-app: {}
            f:spec:
              f:containers:
                k:{"name":"autoscaler"}:
                  .: {}
                  f:command: {}
                  f:image: {}
                  f:imagePullPolicy: {}
                  f:livenessProbe:
                    .: {}
                    f:failureThreshold: {}
                    f:httpGet:
                      .: {}
                      f:path: {}
                      f:port: {}
                      f:scheme: {}
                    f:initialDelaySeconds: {}
                    f:periodSeconds: {}
                    f:successThreshold: {}
                    f:timeoutSeconds: {}
                  f:name: {}
                  f:resources:
                    .: {}
                    f:limits:
                      .: {}
                      f:cpu: {}
                      f:memory: {}
                    f:requests:
                      .: {}
                      f:cpu: {}
                      f:memory: {}
                  f:terminationMessagePath: {}
                  f:terminationMessagePolicy: {}
              f:dnsPolicy: {}
              f:nodeSelector: {}
              f:priorityClassName: {}
              f:restartPolicy: {}
              f:schedulerName: {}
              f:securityContext: {}
              f:serviceAccount: {}
              f:serviceAccountName: {}
              f:terminationGracePeriodSeconds: {}
              f:tolerations: {}
      manager: helm
      operation: Update
      time: '2025-06-10T20:16:30Z'
    - apiVersion: apps/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:spec:
          f:template:
            f:metadata:
              f:annotations:
                f:cattle.io/timestamp: {}
      manager: agent
      operation: Update
      time: '2025-06-12T03:39:45Z'
    - apiVersion: apps/v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:deployment.kubernetes.io/revision: {}
        f:status:
          f:availableReplicas: {}
          f:conditions:
            .: {}
            k:{"type":"Available"}:
              .: {}
              f:lastTransitionTime: {}
              f:lastUpdateTime: {}
              f:message: {}
              f:reason: {}
              f:status: {}
              f:type: {}
            k:{"type":"Progressing"}:
              .: {}
              f:lastTransitionTime: {}
              f:lastUpdateTime: {}
              f:message: {}
              f:reason: {}
              f:status: {}
              f:type: {}
          f:observedGeneration: {}
          f:readyReplicas: {}
          f:replicas: {}
          f:updatedReplicas: {}
      manager: kube-controller-manager
      operation: Update
      subresource: status
      time: '2025-06-12T07:32:07Z'
  name: rke2-coredns-rke2-coredns-autoscaler
  namespace: kube-system
  resourceVersion: '982019'
  uid: 36eaa867-abb2-4d69-87d4-b00f73c04179
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/instance: rke2-coredns
      app.kubernetes.io/name: rke2-coredns-autoscaler
      k8s-app: kube-dns-autoscaler
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      annotations:
        cattle.io/timestamp: '2025-06-12T03:39:48Z'
        checksum/configmap: ab6e5167da89813194a8fa3b9994e9f26e04ab36dbbd340c6267b1460b17e4c8
        scheduler.alpha.kubernetes.io/tolerations: '[{"key":"CriticalAddonsOnly", "operator":"Exists"}]'
      creationTimestamp: null
      labels:
        app.kubernetes.io/instance: rke2-coredns
        app.kubernetes.io/name: rke2-coredns-autoscaler
        k8s-app: kube-dns-autoscaler
    spec:
      containers:
        - command:
            - /cluster-proportional-autoscaler
            - '--namespace=kube-system'
            - '--configmap=rke2-coredns-rke2-coredns-autoscaler'
            - '--target=Deployment/rke2-coredns-rke2-coredns'
            - '--logtostderr=true'
            - '--v=2'
          image: >-
            registry.rancher.com/rancher/hardened-cluster-autoscaler:v1.10.2-build20250507
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 10
          name: autoscaler
          resources:
            limits:
              cpu: 100m
              memory: 64Mi
            requests:
              cpu: 25m
              memory: 16Mi
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
      dnsPolicy: ClusterFirst
      nodeSelector:
        kubernetes.io/os: linux
      priorityClassName: system-cluster-critical
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      serviceAccount: rke2-coredns-rke2-coredns-autoscaler
      serviceAccountName: rke2-coredns-rke2-coredns-autoscaler
      terminationGracePeriodSeconds: 30
      tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        - effect: NoExecute
          key: node-role.kubernetes.io/etcd
          operator: Exists
status:
  availableReplicas: 1
  conditions:
    - lastTransitionTime: '2025-06-10T20:16:30Z'
      lastUpdateTime: '2025-06-12T03:39:51Z'
      message: >-
        ReplicaSet "rke2-coredns-rke2-coredns-autoscaler-5c8dcc4c97" has
        successfully progressed.
      reason: NewReplicaSetAvailable
      status: 'True'
      type: Progressing
    - lastTransitionTime: '2025-06-12T07:32:07Z'
      lastUpdateTime: '2025-06-12T07:32:07Z'
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: 'True'
      type: Available
  observedGeneration: 2
  readyReplicas: 1
  replicas: 1
  updatedReplicas: 1
